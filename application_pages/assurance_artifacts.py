import streamlit as st

def main():
    st.header("Conceptual AI Assurance Artifacts: Model Cards & Data Cards")
    st.markdown("Beyond the risk register, robust AI assurance relies on comprehensive documentation artifacts that enhance transparency, accountability, and explainability. Two critical examples are **Model Cards** and **Data Cards**. This section outlines their conceptual templates and guidance.\n\n### Model Cards\nModel Cards provide a comprehensive summary of an AI model's key facts, enhancing transparency and accountability. They are intended to document a model's performance, behavior, and intended use for various stakeholders.\n\n**Key Components of a Model Card:**\n*   **Model Details**:\n    *   Model Name, Version, Developer, Date.\n    *   Intended Use Cases and Context.\n    *   Out-of-Scope Use Cases (Limitations).\n*   **Training Data Characteristics**:\n    *   Description of the training dataset(s).\n    *   Data collection process and provenance.\n    *   Potential biases, sensitive attributes, or demographic information within the data.\n*   **Performance Metrics**:\n    *   Quantitative metrics (e.g., accuracy, precision, recall, F1-score) for relevant subgroups.\n    *   Fairness metrics (e.g., demographic parity, equalized odds) if applicable.\n    *   Performance benchmarks against baselines.\n*   **Ethical Considerations**:\n    *   Potential societal impacts, positive and negative.\n    *   Risks identified (linking to Risk Register).\n    *   Mitigation strategies for ethical concerns.\n*   **Usage Guidelines**:\n    *   Instructions for appropriate model deployment and interaction.\n    *   Monitoring and maintenance procedures.\n    *   Responsible party for model oversight.\n\n### Data Cards\nData Cards are essential for documenting the provenance and characteristics of datasets used in AI. They ensure transparency around data collection, processing, and potential biases, which are critical for addressing data-related risks.\n\n**Key Components of a Data Card:**\n*   **Dataset Overview**:\n    *   Dataset Name, Creator, Version, Date.\n    *   Purpose of the dataset.\n    *   Description of data contents (features, labels).\n    *   Statistics (e.g., distribution of features, missing values).\n    *   Demographic or sensitive information present.\n    *   Potential biases, limitations, or under-representation.\n*   **Data Collection Process**:\n    *   How the data was collected (sources, methods).\n    *   Any preprocessing or cleaning steps applied.\n    *   Anonymization or privacy-preserving techniques used.\n*   **Data Provenance and Lineage**:\n    *   Origin of the data (where it came from).\n    *   History of transformations and modifications.\n    *   Data rights and licensing information.\n*   **Maintenance and Updates**:\n    *   Frequency of updates.\n    *   Responsible party for data stewardship.\n\nThese artifacts are crucial for enabling "effective challenge" and supporting regulatory compliance by providing clear, auditable evidence of responsible AI development and deployment. They directly inform the `Data` and `Model` risk categories and are integral to the `Map` and `Measure` functions of the NIST AI RMF.")
