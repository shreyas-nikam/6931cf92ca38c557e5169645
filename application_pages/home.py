import streamlit as st
import pandas as pd

def main():
    st.title("AI Model Risk Register & Mitigation Planner")
    st.markdown("This Streamlit application provides a practical guide for identifying, assessing, and managing risks associated with Artificial Intelligence (AI) models. It's designed for risk managers, data engineers, and compliance officers who need to ensure the responsible deployment and continuous assurance of AI systems in regulated environments, such as financial institutions.\n\nWe will explore key concepts from foundational frameworks like SR 11-7 and the NIST AI Risk Management Framework (AI RMF), apply a structured AI risk taxonomy, and develop a simulated AI Risk Register to track and mitigate potential hazards.")

    st.header("Learning Objectives")
    st.markdown("Upon using this application, users will be able to:\n*   Implement an AI Risk Taxonomy to categorize risks into Data, Model, System, Human, and Organizational dimensions.\n*   Facilitate the conceptual assessment of risk likelihood and impact to derive a priority score.\n*   Demonstrate the mapping of mitigation strategies to NIST AI RMF functions and SR 11-7 pillars.\n*   Allow for tracking the status of mitigation efforts over time.\n*   Understand the role and key components of AI assurance artifacts like Model Cards, Data Cards, and comprehensive Risk Reports.\n*   Understand foundational principles of AI risk and assurance relevant to generative AI and agentic systems.")

    st.header("Target Audience")
    st.markdown("This application is tailored for:\n*   **Risk Managers**: Responsible for overseeing and mitigating AI-related risks.\n*   **Financial Data Engineers**: Involved in the development, deployment, and monitoring of AI models in regulated financial contexts.\n*   **AI Ethicists and Compliance Officers**: Focused on ensuring ethical AI practices and regulatory adherence.\n*   **Model Validators**: Tasked with critically reviewing and testing AI models.")

    st.header("AI Risk Management: Context and Foundational Frameworks")
    st.markdown("The increasing adoption of AI, particularly in high-stakes domains like finance, necessitates robust risk management practices. Traditional model risk management frameworks, such as SR 11-7, provide a strong foundation but must be extended to address the unique complexities and emergent risks introduced by AI systems (e.g., hallucinations in LLMs, autonomy creep in agentic systems).\n\nThe **NIST AI Risk Management Framework (AI RMF 1.0)** offers a complementary and voluntary U.S. framework for managing AI risks across all sectors, emphasizing trustworthiness attributes like validity, reliability, safety, security, transparency, fairness, accountability, and privacy-preservation.\n\nKey principles we will explore include:\n*   **SR 11-7 (2011)**: Foundational U.S. guidance for model risk management in financial institutions, defining model risk as the potential for adverse outcomes from incorrect or misused models. It emphasizes effective challenge and robust governance.\n*   **NIST AI RMF 1.0 (2023)**: A framework to promote trustworthy AI by improving the ability to incorporate trustworthiness considerations into AI product design, development, use, and evaluation. It outlines four core functions: **Govern, Map, Measure, Manage**.\n\nThese frameworks collectively provide a structured approach to identifying, assessing, mitigating, and monitoring AI-specific risks, ensuring both regulatory compliance and responsible AI deployment.")

    st.header("AI Risk Taxonomy: A Multidimensional Approach")
    st.markdown("A systematic classification of AI risks is crucial for comprehensive risk management. Risks are categorized across five critical dimensions, ensuring a holistic view across the entire AI lifecycle.\n\n1.  **Data Risks**: Pertain to the quality, provenance, relevance, and privacy of data used in AI systems.\n    *   *Examples*: Data drift, poor data quality, biased training data, data privacy breaches, lack of data provenance.\n2.  **Model Risks**: Associated with the AI model itself, including its design, performance, and interpretability.\n    *   *Examples*: Algorithmic bias, low accuracy/reliability, lack of robustness, model drift, interpretability challenges, hallucinations (LLMs).\n3.  **System Risks**: Relate to the integration, architecture, and security of the AI system within broader IT infrastructure.\n    *   *Examples*: Integration flaws, architectural vulnerabilities, AI supply chain risks, API security issues, scalability problems, error propagation.\n4.  **Human Risks**: Involve human interaction with AI, including misuse, over-reliance, and challenges in oversight.\n    *   *Examples*: Misinterpretation of AI outputs, over-reliance on AI, autonomy creep, loss of human oversight, inadequate human-in-the-loop mechanisms.\n5.  **Organizational Risks**: Encompass governance, policy, and cultural factors within the organization that impact AI risk management.\n    *   *Examples*: Lack of clear AI governance, insufficient ethical guidelines, absence of a responsible AI culture, inadequate resources for AI risk management.\n\nUnderstanding these dimensions allows for targeted identification and mitigation of risks throughout the AI system's lifecycle, from development to ongoing monitoring.")

    st.header("Generating a Synthetic AI Risk Register")
    st.markdown("To simulate a real-world scenario, we will generate a synthetic dataset representing an AI Model Risk Register. This dataset will incorporate the various dimensions of AI risk, likelihood, impact, mitigation strategies, and mappings to regulatory frameworks (NIST AI RMF and SR 11-7). This synthetic data will allow us to demonstrate the principles of AI risk management without needing actual sensitive data.")

    st.header("Initial Data Exploration")
    st.markdown("Before diving into risk scoring and visualization, let's perform an initial exploration of our synthetic AI Risk Register. This step helps us understand the structure, data types, and a quick overview of the content in our dataset.")

    st.header("Calculating Risk Priority Score")
    st.markdown(r"To effectively prioritize risks, we will calculate a `Risk_Priority_Score` based on the assessed `Likelihood` and `Impact`. This score provides a quantitative measure of a risk's severity, enabling risk managers to focus on the most critical issues.\n\nWe will use a simple multiplicative matrix approach, mapping `Low`, `Medium`, `High` to numerical values (1, 2, 3 respectively) for both Likelihood and Impact. The Priority Score ($S$) is then calculated as the product of these numerical values:\n$$\nS = \text{Likelihood}_{\text{numeric}} \times \text{Impact}_{\text{numeric}}\n$$\nThe resulting score will range from 1 (Low Likelihood x Low Impact) to 9 (High Likelihood x High Impact).\n\nThe scoring matrix is as follows:\n$$\n\begin{pmatrix}\n\textbf{Likelihood} / \textbf{Impact} & \textbf{Low (1)} & \textbf{Medium (2)} & \textbf{High (3)} \\\n\textbf{Low (1)} & 1 & 2 & 3 \\\n\textbf{Medium (2)} & 2 & 4 & 6 \\\n\textbf{High (3)} & 3 & 6 & 9\n\end{pmatrix}\n$$\n")

    st.header("Visualizing Risk Categories")
    st.markdown("Understanding the distribution of risks across different categories is fundamental for targeted risk management. This visualization provides a clear overview of which AI risk dimensions (Data, Model, System, Human, Organizational) are most prevalent in our register.")

    st.header("Visualizing Likelihood vs. Impact")
    st.markdown("The Likelihood vs. Impact heatmap is a powerful tool for visualizing the overall risk profile. It shows the concentration of risks based on their assessed probability of occurrence and their potential severity. High-priority risks will typically fall into the "High Likelihood" and "High Impact" quadrants.")

    st.header("Visualizing Risk Status")
    st.markdown("Tracking the `Status` of identified risks is essential for monitoring mitigation progress and overall risk management effectiveness. This visualization provides a snapshot of where the organization stands in addressing its AI risks.")

    st.header("Mapping Risks to NIST AI RMF Functions")
    st.markdown("The NIST AI RMF (Risk Management Framework) provides a structured approach to managing AI risks through four core functions: Govern, Map, Measure, and Manage. Understanding how identified risks align with these functions helps in strategizing mitigation actions within the framework.\n\n*   **Govern**: Fostering a culture of risk management.\n*   **Map**: Identifying risks.\n*   **Measure**: Evaluating and analyzing risks.\n*   **Manage**: Acting to address risks.")

    st.header("Mapping Risks to SR 11-7 Pillars")
    st.markdown("For financial institutions, SR 11-7 provides essential guidance on model risk management, structured around key pillars: Development/Implementation, Validation, Governance, and Ongoing Monitoring. Mapping AI risks to these pillars ensures that AI risk management integrates with existing regulatory compliance requirements.")

    st.header("Updating Risk Status")
    st.markdown("The AI Risk Register is a living document that requires continuous updates as mitigation efforts progress. This section demonstrates how to programmatically update the `Status` of a specific risk once actions have been taken or new information becomes available.")

    st.header("Conceptual AI Assurance Artifacts: Model Cards & Data Cards")
    st.markdown("Beyond the risk register, robust AI assurance relies on comprehensive documentation artifacts that enhance transparency, accountability, and explainability. Two critical examples are **Model Cards** and **Data Cards**. This section outlines their conceptual templates and guidance.\n\n### Model Cards\nModel Cards provide a comprehensive summary of an AI model's key facts, enhancing transparency and accountability. They are intended to document a model's performance, behavior, and intended use for various stakeholders.\n\n**Key Components of a Model Card:**\n*   **Model Details**:\n    *   Model Name, Version, Developer, Date.\n    *   Intended Use Cases and Context.\n    *   Out-of-Scope Use Cases (Limitations).\n*   **Training Data Characteristics**:\n    *   Description of the training dataset(s).\n    *   Data collection process and provenance.\n    *   Potential biases, sensitive attributes, or demographic information within the data.\n*   **Performance Metrics**:\n    *   Quantitative metrics (e.g., accuracy, precision, recall, F1-score) for relevant subgroups.\n    *   Fairness metrics (e.g., demographic parity, equalized odds) if applicable.\n    *   Performance benchmarks against baselines.\n*   **Ethical Considerations**:\n    *   Potential societal impacts, positive and negative.\n    *   Risks identified (linking to Risk Register).\n    *   Mitigation strategies for ethical concerns.\n*   **Usage Guidelines**:\n    *   Instructions for appropriate model deployment and interaction.\n    *   Monitoring and maintenance procedures.\n    *   Responsible party for model oversight.\n\n### Data Cards\nData Cards are essential for documenting the provenance and characteristics of datasets used in AI. They ensure transparency around data collection, processing, and potential biases, which are critical for addressing data-related risks.\n\n**Key Components of a Data Card:**\n*   **Dataset Overview**:\n    *   Dataset Name, Creator, Version, Date.\n    *   Purpose of the dataset.\n    *   Description of data contents (features, labels).\n    *   Statistics (e.g., distribution of features, missing values).\n    *   Demographic or sensitive information present.\n    *   Potential biases, limitations, or under-representation.\n*   **Data Collection Process**:\n    *   How the data was collected (sources, methods).\n    *   Any preprocessing or cleaning steps applied.\n    *   Anonymization or privacy-preserving techniques used.\n*   **Data Provenance and Lineage**:\n    *   Origin of the data (where it came from).\n    *   History of transformations and modifications.\n    *   Data rights and licensing information.\n*   **Maintenance and Updates**:\n    *   Frequency of updates.\n    *   Responsible party for data stewardship.\n\nThese artifacts are crucial for enabling "effective challenge" and supporting regulatory compliance by providing clear, auditable evidence of responsible AI development and deployment. They directly inform the `Data` and `Model` risk categories and are integral to the `Map` and `Measure` functions of the NIST AI RMF.")

    st.header("Generating a Comprehensive AI Risk Report")
    st.markdown("A comprehensive AI Risk Report summarizes the key findings from the risk register, providing stakeholders with an actionable overview of identified risks, their severity, and mitigation progress. This report is vital for communication, governance, and demonstrating compliance.")

    st.header("Conclusion")
    st.markdown("This Streamlit application has guided you through the essential steps of establishing and managing an AI Model Risk Register, incorporating principles from SR 11-7 and the NIST AI Risk Management Framework. We've covered:\n\n*   **Understanding AI Risk Taxonomy**: Categorizing risks into Data, Model, System, Human, and Organizational dimensions.\n*   **Quantifying Risk Severity**: Calculating `Risk_Priority_Scores` based on `Likelihood` and `Impact`.\n*   **Visualizing Risk Landscape**: Using various charts to interpret risk distributions and priorities.\n*   **Tracking Mitigation Efforts**: Demonstrating how to update risk statuses dynamically.\n*   **Leveraging Assurance Artifacts**: Outlining the conceptual importance of Model Cards and Data Cards.\n*   **Generating Actionable Reports**: Creating a comprehensive summary for stakeholders.\n\nBy applying these structured approaches, risk managers and data engineers can proactively identify, assess, mitigate, and monitor AI-specific risks, fostering trust, ensuring compliance, and supporting the responsible deployment of AI within their organizations. Continuous adaptation and monitoring are key to navigating the evolving landscape of AI risks.")